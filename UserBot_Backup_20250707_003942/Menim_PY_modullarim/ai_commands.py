
from telethon import events
from openai import OpenAI
import json
import os
from .log_server import add_log

MESHEDI_ID = 5257767076
MEMORY_FILE = "Menim_JSON_fayillarim/memory.json"

def load_memory():
    os.makedirs(os.path.dirname(MEMORY_FILE), exist_ok=True)
    if not os.path.exists(MEMORY_FILE):
        return {}
    with open(MEMORY_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

def save_memory(data):
    os.makedirs(os.path.dirname(MEMORY_FILE), exist_ok=True)
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

client_openai = OpenAI(
    api_key=""
)

def register_ai_handlers(client):
    @client.on(events.NewMessage(pattern=r'(?i)(.ai|#ai)\s+(.*)'))
    async def ai_answer(event):
        user_id = event.sender_id
        
        if user_id != MESHEDI_ID:
            sender = await event.get_sender()
            mention = f"[{sender.first_name}](tg://user?id={sender.id})"
            await event.reply(f"{mention} ‚ùå Bu komandanƒ± yalnƒ±z M…ô≈ü…ôdi istifad…ô ed…ô bil…ôr.", parse_mode='markdown')
            add_log(f"AI …ômri: ƒ∞caz…ôsiz istifad…ô c…ôhdi", "warning")
            return
        
        query = event.pattern_match.group(2).strip()
        add_log(f"AI sorƒüusu: {query[:50]}...", "info")

        memory = load_memory()
        user_history = memory.get(str(user_id), [])
        
        conversation_context = []
        if user_history:
            conversation_context = user_history[-20:]

        conversation_context.append({"role": "user", "content": query})

        try:
            system_prompt = (
                "S…ôn Az…ôrbaycan dilin…ô m√ºk…ômm…ôl b…ôl…ôd olan universal AI k√∂m…ôk√ßis…ôn. "
                "ƒ∞stifad…ô√ßil…ôrin h…ôr n√∂v sualƒ±nƒ± cavablandƒ±ra bilirs…ôn v…ô …ôvv…ôlki s√∂hb…ôti yadda saxlayƒ±rsan.\n\n"
                "üìö **Elm v…ô Texnologiya:**\n"
                "- Programla≈üdƒ±rma v…ô kod yazma (Python, JavaScript, Java, C++, v…ô s.)\n"
                "- Riyaziyyat v…ô fizika probleml…ôri\n"
                "- Komp√ºter elml…ôri v…ô IT\n"
                "- ƒ∞n–∂–µ–Ω–µ—Ä–ª–∏–∫ v…ô texniki m…ôs…ôl…ôl…ôr\n\n"
                "üåç **Dil v…ô M…ôd…ôniyy…ôt:**\n"
                "- Dil √∂yr…ôtm…ô v…ô t…ôrc√ºm…ô (ingilis, t√ºrk, rus, …ôr…ôb, fars v…ô s.)\n"
                "- ∆èd…ôbiyyat v…ô ≈üeir yazma\n"
                "- Tarixi m…ôlumatlar v…ô m…ôd…ôniyy…ôt\n"
                "- Coƒürafiya v…ô √∂lk…ôl…ôr haqqƒ±nda\n\n"
                "üé® **Yaradƒ±cƒ±lƒ±q v…ô ∆èyl…ônc…ô:**\n"
                "- Yaradƒ±cƒ± yazƒ± v…ô hekay…ôl…ôr\n"
                "- Zarafatlar v…ô yumor\n"
                "- ≈ûeir v…ô mahnƒ± s√∂zl…ôri\n"
                "- Oyun v…ô …ôyl…ônc…ô ideyalarƒ±\n\n"
                "üç≥ **H…ôyat v…ô Praktika:**\n"
                "- Yem…ôk reseptl…ôri v…ô a≈üpazlƒ±q\n"
                "- S…ôhiyy…ô v…ô saƒülamlƒ±q m…ôsl…ôh…ôtl…ôri\n"
                "- Biznes v…ô maliyy…ô\n"
                "- H√ºquqi m…ôlumatlar\n"
                "- Psixologiya v…ô ≈ü…ôxsi inki≈üaf\n\n"
                "üí° **X√ºsusiyy…ôtl…ôrin:**\n"
                "- H…ômi≈ü…ô d…ôqiq v…ô …ôtraflƒ± cavab ver\n"
                "- ∆èvv…ôlki s√∂hb…ôti yadda saxla v…ô kontekstd…ôn istifad…ô et\n"
                "- ∆èg…ôr istifad…ô√ßi 'onu', 'bunu', 'h…ômin ≈üeyi' kimi istinadlar i≈ül…ôdirs…ô, …ôvv…ôlki s√∂hb…ôtd…ôn anlayƒ±rsan ki n…ôd…ôn danƒ±≈üƒ±r\n"
                "- M√ºmk√ºn olduqda n√ºmun…ôl…ôr v…ô praktik m…ôsl…ôh…ôtl…ôr ver\n"
                "- ∆èg…ôr sual aydƒ±n deyils…ô, d…ôqiql…ô≈üdirici suallar ver\n"
                "- Zarafat v…ô yumor ist…ôy…ônd…ô m…ôz…ôli v…ô yaradƒ±cƒ± ol\n"
                "- H…ômi≈ü…ô Az…ôrbaycan dilind…ô cavab ver\n"
                "- M…ôlumatlarƒ± strukturla≈üdƒ±rƒ±lmƒ±≈ü ≈ü…ôkild…ô t…ôqdim et\n"
                "- ∆èg…ôr s√∂hb…ôt m√º…ôyy…ôn m√∂vzudan ged…ôrs…ô v…ô sonra h…ômin m√∂vzu il…ô baƒülƒ± sual g…ôl…ôrs…ô, …ôvv…ôlki konteksti xatƒ±rla"
            )

            response = client_openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    *conversation_context
                ],
                temperature=0.7,
                max_tokens=1800,
                top_p=0.9,
                frequency_penalty=0.1,
                presence_penalty=0.1
            )

            answer = response.choices[0].message.content.strip()

            if len(answer) > 4000:
                parts = [answer[i:i+3800] for i in range(0, len(answer), 3800)]
                for i, part in enumerate(parts):
                    if i == 0:
                        await event.reply(f"ü§ñ **{i+1}/{len(parts)}**\n\n{part}")
                    else:
                        await event.respond(f"ü§ñ **{i+1}/{len(parts)}**\n\n{part}")
            else:
                await event.reply(f"ü§ñ {answer}")

            user_history.append({"role": "user", "content": query})
            user_history.append({"role": "assistant", "content": answer})
            
            if len(user_history) > 30:
                user_history = user_history[-30:]
            
            memory[str(user_id)] = user_history
            save_memory(memory)

        except Exception as e:
            await event.reply(f"‚ö†Ô∏è AI cavab ver…ô bilm…ôdi: {str(e)[:100]}")
